{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.backends import cudnn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "TRAIN_PATH = \"../data/train.csv\"\n",
    "VALID_PATH = \"../data/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dataset_Train(path):\n",
    "    df = pd.read_csv(path, encoding='big5')  ## Read data\n",
    "    df.drop(columns=df.columns[:3], inplace=True) ## Remove first three columns\n",
    "    df.replace('NR', 0, inplace=True)             ## Replace NR to 0\n",
    "    df = df.astype(np.float)\n",
    "    raw_data = df.to_numpy()\n",
    "    # raw_data[raw_data<0] = 0\n",
    "\n",
    "    month_data = {}\n",
    "    for month in range(12):\n",
    "        sample = np.empty([18, 480])\n",
    "        for day in range(20):\n",
    "            sample[:, day * 24 : (day + 1) * 24] = raw_data[18 * (20 * month + day) : 18 * (20 * month + day + 1), :]\n",
    "        month_data[month] = sample\n",
    "\n",
    "    x = np.empty([12 * 471, 18 * 9], dtype = float)\n",
    "    y = np.empty([12 * 471, 1], dtype = float)\n",
    "    for month in range(12):\n",
    "        for day in range(20):\n",
    "            for hour in range(24):\n",
    "                if day == 19 and hour > 14:\n",
    "                    continue\n",
    "                x[month * 471 + day * 24 + hour, :] = month_data[month][:,day * 24 + hour : day * 24 + hour + 9].reshape(1, -1) #vector dim:18*9 (9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9)\n",
    "                y[month * 471 + day * 24 + hour, 0] = month_data[month][9, day * 24 + hour + 9] #value\n",
    "\n",
    "    x = np.insert(x, x.shape[1], values=1, axis=1)\n",
    "\n",
    "    mean_x = np.mean(x, axis=0) #18 * 9 \n",
    "    std_x = np.std(x, axis=0) #18 * 9 \n",
    "    max_x = np.max(x, axis=0)\n",
    "    min_x = np.min(x, axis=0)\n",
    "\n",
    "    for i in range(len(x)): #12 * 471\n",
    "        for j in range(len(x[0])): #18 * 9 \n",
    "            if std_x[j] != 0:\n",
    "    #             x[i][j] = (x[i][j] - mean_x[j]) / std_x[j]\n",
    "                x[i][j] = (x[i][j] - min_x[j]) / (max_x[j] - min_x[j])\n",
    "            \n",
    "    return torch.tensor(x, device=device).float(), torch.tensor(y, device=device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dataset_Test(path):\n",
    "    testdata = pd.read_csv(VALID_PATH, header = None, encoding = 'big5')\n",
    "    test_data = testdata.iloc[:, 2:]\n",
    "    test_data[test_data == 'NR'] = 0\n",
    "    test_data = test_data.astype(np.float)\n",
    "    test_data = test_data.to_numpy()\n",
    "    test_x = np.empty([240, 18*9], dtype = float)\n",
    "    for i in range(240):\n",
    "        test_x[i, :] = test_data[18 * i: 18* (i + 1), :].reshape(1, -1)\n",
    "\n",
    "    # test_data[test_data < 0] = 0\n",
    "\n",
    "\n",
    "    for i in range(len(test_x)):\n",
    "        for j in range(len(test_x[0])):\n",
    "            if std_x[j] != 0:\n",
    "    #             test_x[i][j] = (test_x[i][j] - mean_x[j]) / std_x[j]\n",
    "                test_x[i][j] = (test_x[i][j] - min_x[j]) / (max_x[j] - min_x[j])\n",
    "\n",
    "    test_x = np.insert(test_x, test_x.shape[1], values=1, axis=1)\n",
    "    \n",
    "    return torch.tensor(test_x, device=device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save_Weight(file_name):\n",
    "    with open(file_name, mode='w', newline='') as submit_file:\n",
    "        csv_writer = csv.writer(submit_file)\n",
    "        header = ['id', 'value']\n",
    "        print(header)\n",
    "        csv_writer.writerow(header)\n",
    "        for i in range(240):\n",
    "            row = ['id_' + str(i), ans_y[i][0]]\n",
    "            csv_writer.writerow(row)\n",
    "            print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(My_DNN, self).__init__()\n",
    "        self.base = nn.Sequential(\n",
    "            nn.Linear(163, 512),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.PReLU(),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, std=0.001)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base(x)\n",
    "        return x        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folder: 1 epoch: 1/100: : 1000it [00:00, 10879.77it/s, loss=0.156499]         \n",
      "Folder: 1 epoch: 2/100: : 1000it [00:00, 10974.57it/s, loss=0.471378]         \n",
      "Folder: 1 epoch: 3/100: : 1000it [00:00, 9744.79it/s, loss=26.119038]          \n",
      "Folder: 1 epoch: 4/100: : 1000it [00:00, 10322.38it/s, loss=403.552216]         \n",
      "Folder: 1 epoch: 5/100: : 1000it [00:00, 9340.66it/s, loss=3236.964111]          \n",
      "Folder: 1 epoch: 6/100: : 1000it [00:00, 9201.67it/s, loss=882.587280]          \n",
      "Folder: 1 epoch: 7/100: : 1000it [00:00, 8334.45it/s, loss=189.529678]          \n",
      "Folder: 1 epoch: 8/100: : 1000it [00:00, 7751.78it/s, loss=45.526207]          \n",
      "Folder: 1 epoch: 9/100: : 1000it [00:00, 10064.08it/s, loss=13.596735]         \n",
      "Folder: 1 epoch: 10/100: : 1000it [00:00, 9445.57it/s, loss=5.506054]          \n",
      "Folder: 1 epoch: 11/100: : 1000it [00:00, 8926.06it/s, loss=3.633015]          \n",
      "Folder: 1 epoch: 12/100: : 1000it [00:00, 10479.11it/s, loss=3.684501]         \n",
      "Folder: 1 epoch: 13/100: : 1000it [00:00, 10557.47it/s, loss=5.169291]         \n",
      "Folder: 1 epoch: 14/100: : 1000it [00:00, 9073.08it/s, loss=9.115964]          \n",
      "Folder: 1 epoch: 15/100: : 1000it [00:00, 8875.91it/s, loss=19.202291]          \n",
      "Folder: 1 epoch: 16/100: : 1000it [00:00, 9771.90it/s, loss=47.065399]          \n",
      "Folder: 1 epoch: 17/100: : 1000it [00:00, 9348.10it/s, loss=129.781708]          \n",
      "Folder: 1 epoch: 18/100: : 1000it [00:00, 9653.37it/s, loss=375.763336]          \n",
      "Folder: 1 epoch: 19/100: : 1000it [00:00, 10282.95it/s, loss=959.851562]         \n",
      "Folder: 1 epoch: 20/100: : 1000it [00:00, 9030.53it/s, loss=1257.455444]          \n",
      "Folder: 1 epoch: 21/100: : 1000it [00:00, 8853.54it/s, loss=837.762451]          \n",
      "Folder: 1 epoch: 22/100: : 1000it [00:00, 9497.18it/s, loss=414.458740]          \n",
      "Folder: 1 epoch: 23/100: : 1000it [00:00, 8309.11it/s, loss=211.196487]          \n",
      "Folder: 1 epoch: 24/100: : 1000it [00:00, 7901.76it/s, loss=140.681747]          \n",
      "Folder: 1 epoch: 25/100: : 1000it [00:00, 8884.11it/s, loss=136.711319]          \n",
      "Folder: 1 epoch: 26/100: : 1000it [00:00, 9348.81it/s, loss=187.751984]          \n",
      "Folder: 1 epoch: 27/100: : 1000it [00:00, 10460.71it/s, loss=319.804016]         \n",
      "Folder: 1 epoch: 28/100: : 1000it [00:00, 8678.49it/s, loss=568.490295]          \n",
      "Folder: 1 epoch: 29/100: : 1000it [00:00, 9250.68it/s, loss=860.793030]          \n",
      "Folder: 1 epoch: 30/100: : 1000it [00:00, 8814.41it/s, loss=924.373718]          \n",
      "Folder: 1 epoch: 31/100: : 1000it [00:00, 9010.51it/s, loss=712.465088]          \n",
      "Folder: 1 epoch: 32/100: : 1000it [00:00, 9617.10it/s, loss=470.675385]          \n",
      "Folder: 1 epoch: 33/100: : 1000it [00:00, 9502.38it/s, loss=323.893494]          \n",
      "Folder: 1 epoch: 34/100: : 1000it [00:00, 10248.16it/s, loss=264.987579]         \n",
      "Folder: 1 epoch: 35/100: : 1000it [00:00, 10686.81it/s, loss=270.159943]         \n",
      "Folder: 1 epoch: 36/100: : 1000it [00:00, 9600.17it/s, loss=333.634460]          \n",
      "Folder: 1 epoch: 37/100: : 1000it [00:00, 8971.24it/s, loss=459.778656]          \n",
      "Folder: 1 epoch: 38/100: : 1000it [00:00, 8686.72it/s, loss=630.183838]          \n",
      "Folder: 1 epoch: 39/100: : 1000it [00:00, 7377.40it/s, loss=759.392700]          \n",
      "Folder: 1 epoch: 40/100: : 1000it [00:00, 8347.52it/s, loss=747.674072]          \n",
      "Folder: 1 epoch: 41/100: : 1000it [00:00, 9009.29it/s, loss=621.438293]          \n",
      "Folder: 1 epoch: 42/100: : 1000it [00:00, 9967.10it/s, loss=485.269287]          \n",
      "Folder: 1 epoch: 43/100: : 1000it [00:00, 9593.62it/s, loss=397.675690]          \n",
      "Folder: 1 epoch: 44/100: : 1000it [00:00, 10223.65it/s, loss=366.702820]         \n",
      "Folder: 1 epoch: 45/100: : 1000it [00:00, 7618.08it/s, loss=386.963318]          \n",
      "Folder: 1 epoch: 46/100: : 1000it [00:00, 9802.13it/s, loss=453.743622]          \n",
      "Folder: 1 epoch: 47/100: : 1000it [00:00, 8442.34it/s, loss=555.149231]          \n",
      "Folder: 1 epoch: 48/100: : 1000it [00:00, 9129.82it/s, loss=654.717224]          \n",
      "Folder: 1 epoch: 49/100: : 1000it [00:00, 9654.48it/s, loss=696.588806]          \n",
      "Folder: 1 epoch: 50/100: : 1000it [00:00, 9168.36it/s, loss=657.610474]          \n",
      "Folder: 1 epoch: 51/100: : 1000it [00:00, 10667.86it/s, loss=574.549255]         \n",
      "Folder: 1 epoch: 52/100: : 1000it [00:00, 8187.41it/s, loss=498.552979]          \n",
      "Folder: 1 epoch: 53/100: : 1000it [00:00, 7694.54it/s, loss=456.769684]          \n",
      "Folder: 1 epoch: 54/100: : 1000it [00:00, 7110.93it/s, loss=455.516724]          \n",
      "Folder: 1 epoch: 55/100: : 1000it [00:00, 7346.53it/s, loss=492.287903]          \n",
      "Folder: 1 epoch: 56/100: : 1000it [00:00, 9605.55it/s, loss=557.478699]          \n",
      "Folder: 1 epoch: 57/100: : 1000it [00:00, 8454.67it/s, loss=628.371826]          \n",
      "Folder: 1 epoch: 58/100: : 1000it [00:00, 9122.36it/s, loss=670.706726]          \n",
      "Folder: 1 epoch: 59/100: : 1000it [00:00, 10243.05it/s, loss=662.287048]         \n",
      "Folder: 1 epoch: 60/100: : 1000it [00:00, 8130.18it/s, loss=615.374756]          \n",
      "Folder: 1 epoch: 61/100: : 1000it [00:00, 7546.10it/s, loss=563.411499]          \n",
      "Folder: 1 epoch: 62/100: : 1000it [00:00, 7066.03it/s, loss=533.883545]          \n",
      "Folder: 1 epoch: 63/100: : 1000it [00:00, 10333.95it/s, loss=539.301392]         \n",
      "Folder: 1 epoch: 64/100: : 1000it [00:00, 10524.78it/s, loss=579.853210]         \n",
      "Folder: 1 epoch: 65/100: : 1000it [00:00, 7875.74it/s, loss=642.608765]          \n",
      "Folder: 1 epoch: 66/100: : 1000it [00:00, 7870.85it/s, loss=698.340515]          \n",
      "Folder: 1 epoch: 67/100: : 1000it [00:00, 6845.04it/s, loss=714.395508]          \n",
      "Folder: 1 epoch: 68/100: : 1000it [00:00, 7790.63it/s, loss=686.058960]          \n",
      "Folder: 1 epoch: 69/100: : 1000it [00:00, 7361.35it/s, loss=642.512024]          \n",
      "Folder: 1 epoch: 70/100: : 1000it [00:00, 6961.99it/s, loss=616.878357]          \n",
      "Folder: 1 epoch: 71/100: : 1000it [00:00, 7986.56it/s, loss=624.411438]          \n",
      "Folder: 1 epoch: 72/100: : 1000it [00:00, 7820.34it/s, loss=660.318787]          \n",
      "Folder: 1 epoch: 73/100: : 1000it [00:00, 9516.18it/s, loss=702.243347]          \n",
      "Folder: 1 epoch: 74/100: : 1000it [00:00, 7989.41it/s, loss=720.541016]          \n",
      "Folder: 1 epoch: 75/100: : 1000it [00:00, 9008.37it/s, loss=702.366516]          \n",
      "Folder: 1 epoch: 76/100: : 1000it [00:00, 8159.20it/s, loss=663.955017]          \n",
      "Folder: 1 epoch: 77/100: : 1000it [00:00, 7225.77it/s, loss=632.000610]          \n",
      "Folder: 1 epoch: 78/100: : 1000it [00:00, 7039.37it/s, loss=622.559692]          \n",
      "Folder: 1 epoch: 79/100: : 1000it [00:00, 8329.17it/s, loss=636.198608]          \n",
      "Folder: 1 epoch: 80/100: : 1000it [00:00, 9261.40it/s, loss=660.907166]          \n",
      "Folder: 1 epoch: 81/100: : 1000it [00:00, 9462.98it/s, loss=678.283508]          \n",
      "Folder: 1 epoch: 82/100: : 1000it [00:00, 8659.35it/s, loss=675.321533]          \n",
      "Folder: 1 epoch: 83/100: : 1000it [00:00, 8439.80it/s, loss=654.755249]          \n",
      "Folder: 1 epoch: 84/100: : 1000it [00:00, 6885.34it/s, loss=631.442688]          \n",
      "Folder: 1 epoch: 85/100: : 1000it [00:00, 9022.67it/s, loss=619.805359]          \n",
      "Folder: 1 epoch: 86/100: : 1000it [00:00, 7426.82it/s, loss=625.601379]          \n",
      "Folder: 1 epoch: 87/100: : 1000it [00:00, 9370.13it/s, loss=644.363220]          \n",
      "Folder: 1 epoch: 88/100: : 1000it [00:00, 9309.94it/s, loss=663.912903]          \n",
      "Folder: 1 epoch: 89/100: : 1000it [00:00, 10461.80it/s, loss=671.593689]         \n",
      "Folder: 1 epoch: 90/100: : 1000it [00:00, 10260.06it/s, loss=663.992676]         \n",
      "Folder: 1 epoch: 91/100: : 1000it [00:00, 9198.20it/s, loss=649.846191]          \n",
      "Folder: 1 epoch: 92/100: : 1000it [00:00, 7265.38it/s, loss=642.145508]          \n",
      "Folder: 1 epoch: 93/100: : 1000it [00:00, 8466.07it/s, loss=648.258118]          \n",
      "Folder: 1 epoch: 94/100: : 1000it [00:00, 7120.59it/s, loss=665.439270]          \n",
      "Folder: 1 epoch: 95/100: : 1000it [00:00, 7977.01it/s, loss=682.462524]          \n",
      "Folder: 1 epoch: 96/100: : 1000it [00:00, 8005.22it/s, loss=687.725708]          \n",
      "Folder: 1 epoch: 97/100: : 1000it [00:00, 9264.25it/s, loss=679.748474]          \n",
      "Folder: 1 epoch: 98/100: : 1000it [00:00, 9611.30it/s, loss=668.569946]          \n",
      "Folder: 1 epoch: 99/100: : 1000it [00:00, 7904.42it/s, loss=665.750610]          \n",
      "Folder: 1 epoch: 100/100: : 1000it [00:00, 8339.16it/s, loss=674.410950]          \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folder: 2 epoch: 1/100: : 1000it [00:00, 8820.46it/s, loss=625.751587]          \n",
      "Folder: 2 epoch: 2/100: : 1000it [00:00, 10490.14it/s, loss=618.957764]         \n",
      "Folder: 2 epoch: 3/100: : 1000it [00:00, 9509.66it/s, loss=611.420166]          \n",
      "Folder: 2 epoch: 4/100: : 1000it [00:00, 10189.62it/s, loss=609.541260]         \n",
      "Folder: 2 epoch: 5/100: : 1000it [00:00, 10339.84it/s, loss=613.754944]         \n",
      "Folder: 2 epoch: 6/100: : 1000it [00:00, 8956.39it/s, loss=618.609131]          \n",
      "Folder: 2 epoch: 7/100: : 1000it [00:00, 9202.50it/s, loss=618.259277]          \n",
      "Folder: 2 epoch: 8/100: : 1000it [00:00, 9510.76it/s, loss=612.530884]          \n",
      "Folder: 2 epoch: 9/100: : 1000it [00:00, 8435.63it/s, loss=606.812744]          \n",
      "Folder: 2 epoch: 10/100: : 1000it [00:00, 9571.51it/s, loss=606.275269]          \n",
      "Folder: 2 epoch: 11/100: : 1000it [00:00, 9411.40it/s, loss=610.792175]          \n",
      "Folder: 2 epoch: 12/100: : 1000it [00:00, 7363.13it/s, loss=615.324951]          \n",
      "Folder: 2 epoch: 13/100: : 1000it [00:00, 10622.42it/s, loss=615.283264]         \n",
      "Folder: 2 epoch: 14/100: : 1000it [00:00, 9470.84it/s, loss=611.616760]          \n",
      "Folder: 2 epoch: 15/100: : 1000it [00:00, 9703.60it/s, loss=609.607300]          \n",
      "Folder: 2 epoch: 16/100: : 1000it [00:00, 9544.46it/s, loss=612.616699]          \n",
      "Folder: 2 epoch: 17/100: : 1000it [00:00, 9728.02it/s, loss=618.217163]          \n",
      "Folder: 2 epoch: 18/100: : 1000it [00:00, 9101.79it/s, loss=620.935913]          \n",
      "Folder: 2 epoch: 19/100: : 1000it [00:00, 9513.70it/s, loss=619.022827]          \n",
      "Folder: 2 epoch: 20/100: : 1000it [00:00, 11050.84it/s, loss=616.646118]         \n",
      "Folder: 2 epoch: 21/100: : 1000it [00:00, 10889.01it/s, loss=618.261414]         \n",
      "Folder: 2 epoch: 22/100: : 1000it [00:00, 9275.58it/s, loss=622.491150]          \n",
      "Folder: 2 epoch: 23/100: : 1000it [00:00, 10877.34it/s, loss=624.060486]         \n",
      "Folder: 2 epoch: 24/100: : 1000it [00:00, 8874.58it/s, loss=621.230835]          \n",
      "Folder: 2 epoch: 25/100: : 1000it [00:00, 10084.64it/s, loss=618.402466]         \n",
      "Folder: 2 epoch: 26/100: : 1000it [00:00, 10514.99it/s, loss=619.536499]         \n",
      "Folder: 2 epoch: 27/100: : 1000it [00:00, 10816.14it/s, loss=622.302368]         \n",
      "Folder: 2 epoch: 28/100: : 1000it [00:00, 10347.64it/s, loss=621.770630]         \n",
      "Folder: 2 epoch: 29/100: : 1000it [00:00, 8935.06it/s, loss=618.480347]          \n",
      "Folder: 2 epoch: 30/100: : 1000it [00:00, 9445.04it/s, loss=617.600891]          \n",
      "Folder: 2 epoch: 31/100: : 1000it [00:00, 9726.69it/s, loss=620.378845]          \n",
      "Folder: 2 epoch: 32/100: : 1000it [00:00, 8354.99it/s, loss=622.004639]          \n",
      "Folder: 2 epoch: 33/100: : 1000it [00:00, 9184.66it/s, loss=620.137817]          \n",
      "Folder: 2 epoch: 34/100: : 1000it [00:00, 9202.96it/s, loss=619.367371]          \n",
      "Folder: 2 epoch: 35/100: : 1000it [00:00, 10976.84it/s, loss=622.371216]         \n",
      "Folder: 2 epoch: 36/100: : 1000it [00:00, 10555.80it/s, loss=624.693726]         \n",
      "Folder: 2 epoch: 37/100: : 1000it [00:00, 8804.83it/s, loss=623.483337]          \n",
      "Folder: 2 epoch: 38/100: : 1000it [00:00, 7656.00it/s, loss=623.331360]          \n",
      "Folder: 2 epoch: 39/100: : 1000it [00:00, 6834.78it/s, loss=626.360596]          \n",
      "Folder: 2 epoch: 40/100: : 1000it [00:00, 10113.41it/s, loss=627.219849]         \n",
      "Folder: 2 epoch: 41/100: : 1000it [00:00, 9593.45it/s, loss=625.266785]          \n",
      "Folder: 2 epoch: 42/100: : 1000it [00:00, 9218.76it/s, loss=626.354248]          \n",
      "Folder: 2 epoch: 43/100: : 1000it [00:00, 9363.29it/s, loss=628.320251]          \n",
      "Folder: 2 epoch: 44/100: : 1000it [00:00, 9514.26it/s, loss=626.573181]          \n",
      "Folder: 2 epoch: 45/100: : 1000it [00:00, 9309.71it/s, loss=626.279663]          \n",
      "Folder: 2 epoch: 46/100: : 1000it [00:00, 6422.94it/s, loss=628.612671]          \n",
      "Folder: 2 epoch: 47/100: : 1000it [00:00, 7904.47it/s, loss=627.353699]          \n",
      "Folder: 2 epoch: 48/100: : 1000it [00:00, 10118.00it/s, loss=627.407349]         \n",
      "Folder: 2 epoch: 49/100: : 1000it [00:00, 9746.72it/s, loss=630.122253]          \n",
      "Folder: 2 epoch: 50/100: : 1000it [00:00, 10023.64it/s, loss=628.912781]         \n",
      "Folder: 2 epoch: 51/100: : 1000it [00:00, 10790.46it/s, loss=630.539917]         \n",
      "Folder: 2 epoch: 52/100: : 1000it [00:00, 10325.66it/s, loss=632.401062]         \n",
      "Folder: 2 epoch: 53/100: : 1000it [00:00, 9014.60it/s, loss=631.204285]          \n",
      "Folder: 2 epoch: 54/100: : 1000it [00:00, 6985.92it/s, loss=634.740051]          \n",
      "Folder: 2 epoch: 55/100: : 1000it [00:00, 10772.64it/s, loss=632.473022]         \n",
      "Folder: 2 epoch: 56/100: : 1000it [00:00, 9423.22it/s, loss=635.976318]          \n",
      "Folder: 2 epoch: 57/100: : 1000it [00:00, 10423.01it/s, loss=632.916870]         \n",
      "Folder: 2 epoch: 58/100: : 1000it [00:00, 8584.30it/s, loss=637.842224]          \n",
      "Folder: 2 epoch: 59/100: : 1000it [00:00, 7402.22it/s, loss=630.654114]          \n",
      "Folder: 2 epoch: 60/100: : 1000it [00:00, 10193.07it/s, loss=644.619812]         \n",
      "Folder: 2 epoch: 61/100: : 1000it [00:00, 9329.57it/s, loss=616.721497]          \n",
      "Folder: 2 epoch: 62/100: : 1000it [00:00, 10173.26it/s, loss=680.934875]         \n",
      "Folder: 2 epoch: 63/100: : 1000it [00:00, 10117.09it/s, loss=542.061829]         \n",
      "Folder: 2 epoch: 64/100: : 1000it [00:00, 8583.26it/s, loss=828.045715]          \n",
      "Folder: 2 epoch: 65/100: : 1000it [00:00, 9678.37it/s, loss=444.534363]          \n",
      "Folder: 2 epoch: 66/100: : 1000it [00:00, 7832.84it/s, loss=663.530823]          \n",
      "Folder: 2 epoch: 67/100: : 1000it [00:00, 7612.06it/s, loss=819.006104]          \n",
      "Folder: 2 epoch: 68/100: : 1000it [00:00, 8669.70it/s, loss=474.106171]          \n",
      "Folder: 2 epoch: 69/100: : 1000it [00:00, 10613.20it/s, loss=554.360535]         \n",
      "Folder: 2 epoch: 70/100: : 1000it [00:00, 7395.90it/s, loss=836.278137]          \n",
      "Folder: 2 epoch: 71/100: : 1000it [00:00, 10618.46it/s, loss=600.688538]         \n",
      "Folder: 2 epoch: 72/100: : 1000it [00:00, 10506.25it/s, loss=486.753723]         \n",
      "Folder: 2 epoch: 73/100: : 1000it [00:00, 10451.79it/s, loss=666.331055]         \n",
      "Folder: 2 epoch: 74/100: : 1000it [00:00, 10707.40it/s, loss=778.152222]         \n",
      "Folder: 2 epoch: 75/100: : 1000it [00:00, 7655.15it/s, loss=568.749634]          \n",
      "Folder: 2 epoch: 76/100: : 1000it [00:00, 7375.47it/s, loss=525.907471]          \n",
      "Folder: 2 epoch: 77/100: : 1000it [00:00, 7516.19it/s, loss=697.087158]          \n",
      "Folder: 2 epoch: 78/100: : 1000it [00:00, 9535.93it/s, loss=740.591309]          \n",
      "Folder: 2 epoch: 79/100: : 1000it [00:00, 10570.54it/s, loss=571.457764]         \n",
      "Folder: 2 epoch: 80/100: : 1000it [00:00, 10530.65it/s, loss=556.238525]         \n",
      "Folder: 2 epoch: 81/100: : 1000it [00:00, 7551.41it/s, loss=702.698425]          \n",
      "Folder: 2 epoch: 82/100: : 1000it [00:00, 7815.41it/s, loss=712.279907]          \n",
      "Folder: 2 epoch: 83/100: : 1000it [00:00, 7461.90it/s, loss=575.866516]          \n",
      "Folder: 2 epoch: 84/100: : 1000it [00:00, 8616.41it/s, loss=577.605225]          \n",
      "Folder: 2 epoch: 85/100: : 1000it [00:00, 8344.27it/s, loss=699.677063]          \n",
      "Folder: 2 epoch: 86/100: : 1000it [00:00, 10004.97it/s, loss=686.924988]         \n",
      "Folder: 2 epoch: 87/100: : 1000it [00:00, 8987.52it/s, loss=578.507751]          \n",
      "Folder: 2 epoch: 88/100: : 1000it [00:00, 8976.75it/s, loss=597.803040]          \n",
      "Folder: 2 epoch: 89/100: : 1000it [00:00, 7899.99it/s, loss=698.966187]          \n",
      "Folder: 2 epoch: 90/100: : 1000it [00:00, 7394.53it/s, loss=662.895447]          \n",
      "Folder: 2 epoch: 91/100: : 1000it [00:00, 8688.37it/s, loss=582.188416]          \n",
      "Folder: 2 epoch: 92/100: : 1000it [00:00, 9292.22it/s, loss=626.305664]          \n",
      "Folder: 2 epoch: 93/100: : 1000it [00:00, 10072.00it/s, loss=699.375183]         \n",
      "Folder: 2 epoch: 94/100: : 1000it [00:00, 9725.99it/s, loss=635.083618]          \n",
      "Folder: 2 epoch: 95/100: : 1000it [00:00, 9476.92it/s, loss=593.655029]          \n",
      "Folder: 2 epoch: 96/100: : 1000it [00:00, 9617.12it/s, loss=662.909302]          \n",
      "Folder: 2 epoch: 97/100: : 1000it [00:00, 9217.22it/s, loss=682.078308]          \n",
      "Folder: 2 epoch: 98/100: : 1000it [00:00, 9738.93it/s, loss=609.317017]          \n",
      "Folder: 2 epoch: 99/100: : 1000it [00:00, 9554.07it/s, loss=623.154785]          \n",
      "Folder: 2 epoch: 100/100: : 1000it [00:00, 10079.31it/s, loss=685.679016]         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folder: 3 epoch: 1/100: : 1000it [00:00, 8223.67it/s, loss=663.194092]          \n",
      "Folder: 3 epoch: 2/100: : 1000it [00:00, 9804.79it/s, loss=623.354248]          \n",
      "Folder: 3 epoch: 3/100: : 1000it [00:00, 9635.57it/s, loss=671.970337]          \n",
      "Folder: 3 epoch: 4/100: : 1000it [00:00, 11004.95it/s, loss=682.037476]         \n",
      "Folder: 3 epoch: 5/100: : 1000it [00:00, 7946.77it/s, loss=631.137878]          \n",
      "Folder: 3 epoch: 6/100: : 1000it [00:00, 8135.76it/s, loss=656.458496]          \n",
      "Folder: 3 epoch: 7/100: : 1000it [00:00, 10555.85it/s, loss=688.171082]         "
     ]
    }
   ],
   "source": [
    "## \n",
    "cudnn.benchmark = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "##\n",
    "\n",
    "## 超參數\n",
    "LEARNING_RATE = 0.01\n",
    "N_SPLIT = 5\n",
    "N_EPOCHS = 1\n",
    "##\n",
    "\n",
    "model = My_DNN()\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_MSE = nn.MSELoss()\n",
    "\n",
    "X, y = Dataset_Train(TRAIN_PATH)\n",
    "\n",
    "cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "n = 1\n",
    "# for epoch in range(N_EPOCHS):\n",
    "#     with tqdm(total=N_EPOCHS) as _tqdm:\n",
    "#         _tqdm.set_description('epoch: {}/{}'.format(epoch + 1, N_EPOCHS))\n",
    "\n",
    "#         ## Train\n",
    "#         y_pred = model(X)\n",
    "#         loss = loss_MSE(y_pred, y)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         _tqdm.set_postfix(loss='{:.6f}'.format(loss))\n",
    "#         _tqdm.update(N_EPOCHS)      \n",
    "\n",
    "#     n += 1\n",
    "\n",
    "\n",
    "\n",
    "for train_idx, valid_idx in cv.split(X):\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        with tqdm(total=N_EPOCHS) as _tqdm:\n",
    "            _tqdm.set_description('Folder: {} epoch: {}/{}'.format(n, epoch + 1, N_EPOCHS))\n",
    "            X_train, X_valid = X[train_idx,:].to(device), X[valid_idx,:].to(device)\n",
    "            y_train, y_valid = y[train_idx].to(device), y[valid_idx].to(device)\n",
    "            \n",
    "            \n",
    "            ## Train\n",
    "            y_pred = model(X_train)\n",
    "            loss = loss_MSE(y_pred, y_train)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            ##\n",
    "            \n",
    "            ## Valid\n",
    "            y_pred = model(X_valid)\n",
    "            loss = loss_MSE(y_pred, X_valid)\n",
    "\n",
    "            _tqdm.set_postfix(loss='{:.6f}'.format(loss.item()))\n",
    "            _tqdm.update(1000)        \n",
    "            \n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'K_Fold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-49c352224fc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mN_FOLDS\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK_Fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_FOLDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mweight_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxsize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'K_Fold' is not defined"
     ]
    }
   ],
   "source": [
    "N_FOLDS  = 5\n",
    "train_idx, valid_idx = K_Fold(x.shape[0], 9, N_FOLDS)\n",
    "\n",
    "weight_best = None\n",
    "loss_best = sys.maxsize\n",
    "\n",
    "for i in range(N_FOLDS):\n",
    "    LRGD = LinearRegressionUsingGD(lr=0.06, eps=1e-10,iters=10000)\n",
    "    \n",
    "    x_train = np.asarray([x[idx] for idx in train_idx[i]])\n",
    "    y_train = y[train_idx[i]]\n",
    "    \n",
    "    x_valid = np.asarray([x[idx] for idx in valid_idx[i]])\n",
    "    y_valid = y[valid_idx[i]]\n",
    "    \n",
    "    LRGD.fit(x_train, y_train)\n",
    "    y_pred = LRGD.predict(x_valid)\n",
    "    loss = np.sqrt(np.mean(np.power(y_valid - y_pred, 2)))#rmse\n",
    "    \n",
    "    if loss < loss_best:\n",
    "        weight_best = LRGD.ω\n",
    "        loss_best = loss\n",
    "    \n",
    "    print(\"Folder: {}, Loss: {}\".format(i, loss))\n",
    "    \n",
    "np.save(\"weight.npy\", weight_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
