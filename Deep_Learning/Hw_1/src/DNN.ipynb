{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.backends import cudnn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "TRAIN_PATH = \"../data/train.csv\"\n",
    "VALID_PATH = \"../data/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dataset_Train(path):\n",
    "    df = pd.read_csv(path, encoding='big5')  ## Read data\n",
    "    df.drop(columns=df.columns[:3], inplace=True) ## Remove first three columns\n",
    "    df.replace('NR', 0, inplace=True)             ## Replace NR to 0\n",
    "    df = df.astype(np.float)\n",
    "    raw_data = df.to_numpy()\n",
    "    # raw_data[raw_data<0] = 0\n",
    "\n",
    "    month_data = {}\n",
    "    for month in range(12):\n",
    "        sample = np.empty([18, 480])\n",
    "        for day in range(20):\n",
    "            sample[:, day * 24 : (day + 1) * 24] = raw_data[18 * (20 * month + day) : 18 * (20 * month + day + 1), :]\n",
    "        month_data[month] = sample\n",
    "\n",
    "    x = np.empty([12 * 471, 18 * 9], dtype = float)\n",
    "    y = np.empty([12 * 471, 1], dtype = float)\n",
    "    for month in range(12):\n",
    "        for day in range(20):\n",
    "            for hour in range(24):\n",
    "                if day == 19 and hour > 14:\n",
    "                    continue\n",
    "                x[month * 471 + day * 24 + hour, :] = month_data[month][:,day * 24 + hour : day * 24 + hour + 9].reshape(1, -1) #vector dim:18*9 (9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9)\n",
    "                y[month * 471 + day * 24 + hour, 0] = month_data[month][9, day * 24 + hour + 9] #value\n",
    "\n",
    "    x = np.insert(x, x.shape[1], values=1, axis=1)\n",
    "\n",
    "    mean_x = np.mean(x, axis=0) #18 * 9 \n",
    "    std_x = np.std(x, axis=0) #18 * 9 \n",
    "    max_x = np.max(x, axis=0)\n",
    "    min_x = np.min(x, axis=0)\n",
    "\n",
    "    for i in range(len(x)): #12 * 471\n",
    "        for j in range(len(x[0])): #18 * 9 \n",
    "            if std_x[j] != 0:\n",
    "    #             x[i][j] = (x[i][j] - mean_x[j]) / std_x[j]\n",
    "                x[i][j] = (x[i][j] - min_x[j]) / (max_x[j] - min_x[j])\n",
    "            \n",
    "    return torch.tensor(x, device=device).float(), torch.tensor(y, device=device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dataset_Test(path):\n",
    "    testdata = pd.read_csv(VALID_PATH, header = None, encoding = 'big5')\n",
    "    test_data = testdata.iloc[:, 2:]\n",
    "    test_data[test_data == 'NR'] = 0\n",
    "    test_data = test_data.astype(np.float)\n",
    "    test_data = test_data.to_numpy()\n",
    "    test_x = np.empty([240, 18*9], dtype = float)\n",
    "    for i in range(240):\n",
    "        test_x[i, :] = test_data[18 * i: 18* (i + 1), :].reshape(1, -1)\n",
    "\n",
    "    # test_data[test_data < 0] = 0\n",
    "\n",
    "\n",
    "    for i in range(len(test_x)):\n",
    "        for j in range(len(test_x[0])):\n",
    "            if std_x[j] != 0:\n",
    "    #             test_x[i][j] = (test_x[i][j] - mean_x[j]) / std_x[j]\n",
    "                test_x[i][j] = (test_x[i][j] - min_x[j]) / (max_x[j] - min_x[j])\n",
    "\n",
    "    test_x = np.insert(test_x, test_x.shape[1], values=1, axis=1)\n",
    "    \n",
    "    return torch.tensor(test_x, device=device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save_Weight(file_name):\n",
    "    with open(file_name, mode='w', newline='') as submit_file:\n",
    "        csv_writer = csv.writer(submit_file)\n",
    "        header = ['id', 'value']\n",
    "        print(header)\n",
    "        csv_writer.writerow(header)\n",
    "        for i in range(240):\n",
    "            row = ['id_' + str(i), ans_y[i][0]]\n",
    "            csv_writer.writerow(row)\n",
    "            print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(My_DNN, self).__init__()\n",
    "        self.base = nn.Sequential(\n",
    "            nn.Linear(163, 512),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.PReLU(),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, std=0.001)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base(x)\n",
    "        return x        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 1/1: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s, loss=4134496.500000]\n"
     ]
    }
   ],
   "source": [
    "## \n",
    "cudnn.benchmark = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "##\n",
    "\n",
    "## 超參數\n",
    "LEARNING_RATE = 0.01\n",
    "N_SPLIT = 5\n",
    "N_EPOCHS = 1\n",
    "##\n",
    "\n",
    "model = My_DNN()\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_MSE = nn.MSELoss()\n",
    "\n",
    "X, y = Dataset_Train(TRAIN_PATH)\n",
    "\n",
    "cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "n = 1\n",
    "for epoch in range(N_EPOCHS):\n",
    "    with tqdm(total=N_EPOCHS) as _tqdm:\n",
    "        _tqdm.set_description('epoch: {}/{}'.format(epoch + 1, N_EPOCHS))\n",
    "\n",
    "        ## Train\n",
    "        y_pred = model(X)\n",
    "        loss = loss_MSE(y_pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        y_pred = model(X)\n",
    "        loss = loss_MSE(y_pred, y)\n",
    "        _tqdm.set_postfix(loss='{:.6f}'.format(loss.item()))\n",
    "        _tqdm.update(N_EPOCHS)      \n",
    "\n",
    "    n += 1\n",
    "\n",
    "\n",
    "# for train_idx, valid_idx in cv.split(X):\n",
    "#     model = My_DNN()\n",
    "#     model = model.to(device)\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "#     loss_MSE = nn.MSELoss()\n",
    "#     for epoch in range(N_EPOCHS):\n",
    "#         with tqdm(total=N_EPOCHS) as _tqdm:\n",
    "#             _tqdm.set_description('Folder: {} epoch: {}/{}'.format(n, epoch + 1, N_EPOCHS))\n",
    "#             X_train, X_valid = X[train_idx,:].to(device), X[valid_idx,:].to(device)\n",
    "#             y_train, y_valid = y[train_idx].to(device), y[valid_idx].to(device)\n",
    "            \n",
    "            \n",
    "#             ## Train\n",
    "#             y_pred = model(X_train)\n",
    "#             loss = loss_MSE(y_pred, y_train)\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             ##\n",
    "            \n",
    "#             ## Valid\n",
    "#             y_pred = model(X_valid)\n",
    "#             loss = loss_MSE(y_pred, X_valid)\n",
    "\n",
    "#             _tqdm.set_postfix(loss='{:.6f}'.format(loss.item()))\n",
    "#             _tqdm.update(1000)        \n",
    "            \n",
    "#     n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'K_Fold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-49c352224fc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mN_FOLDS\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK_Fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_FOLDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mweight_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxsize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'K_Fold' is not defined"
     ]
    }
   ],
   "source": [
    "N_FOLDS  = 5\n",
    "train_idx, valid_idx = K_Fold(x.shape[0], 9, N_FOLDS)\n",
    "\n",
    "weight_best = None\n",
    "loss_best = sys.maxsize\n",
    "\n",
    "for i in range(N_FOLDS):\n",
    "    LRGD = LinearRegressionUsingGD(lr=0.06, eps=1e-10,iters=10000)\n",
    "    \n",
    "    x_train = np.asarray([x[idx] for idx in train_idx[i]])\n",
    "    y_train = y[train_idx[i]]\n",
    "    \n",
    "    x_valid = np.asarray([x[idx] for idx in valid_idx[i]])\n",
    "    y_valid = y[valid_idx[i]]\n",
    "    \n",
    "    LRGD.fit(x_train, y_train)\n",
    "    y_pred = LRGD.predict(x_valid)\n",
    "    loss = np.sqrt(np.mean(np.power(y_valid - y_pred, 2)))#rmse\n",
    "    \n",
    "    if loss < loss_best:\n",
    "        weight_best = LRGD.ω\n",
    "        loss_best = loss\n",
    "    \n",
    "    print(\"Folder: {}, Loss: {}\".format(i, loss))\n",
    "    \n",
    "np.save(\"weight.npy\", weight_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
